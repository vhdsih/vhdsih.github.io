<!DOCTYPE html>
<html lang=en>
<head>
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5" />
    <meta name="description" content="《机器学习基石》系列课程（七） 我们已经讨论过了，拥有Break Point k的增长函数mh(N)的上界最大是N的k-1次幂，在第6节的最后，我们提出来VC Bound， 利用该公式，我们可以有这样的推论，如果我们当前的Learning问题满足：  成长函数有Break Point k。 数据量N足够大 能够从假设空间中选择一个g，满足Ein非常小（接近0）。  那么我们就能够说明我们的Lear">
<meta property="og:type" content="article">
<meta property="og:title" content="07 The VC Dimension">
<meta property="og:url" content="https://vhdsih.github.io/2018/10/10/mlfound7/index.html">
<meta property="og:site_name" content="vhdsih">
<meta property="og:description" content="《机器学习基石》系列课程（七） 我们已经讨论过了，拥有Break Point k的增长函数mh(N)的上界最大是N的k-1次幂，在第6节的最后，我们提出来VC Bound， 利用该公式，我们可以有这样的推论，如果我们当前的Learning问题满足：  成长函数有Break Point k。 数据量N足够大 能够从假设空间中选择一个g，满足Ein非常小（接近0）。  那么我们就能够说明我们的Lear">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://vhdsih.github.io/2018/10/10/mlfound7/1.png">
<meta property="og:image" content="https://vhdsih.github.io/2018/10/10/mlfound7/2.png">
<meta property="og:image" content="https://vhdsih.github.io/2018/10/10/mlfound7/3.png">
<meta property="og:image" content="https://vhdsih.github.io/2018/10/10/mlfound7/4.png">
<meta property="og:image" content="https://vhdsih.github.io/2018/10/10/mlfound7/5.png">
<meta property="article:published_time" content="2018-10-10T13:06:44.000Z">
<meta property="article:modified_time" content="2023-10-18T15:19:06.715Z">
<meta property="article:author" content="vhdsih">
<meta property="article:tag" content="林轩田">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://vhdsih.github.io/2018/10/10/mlfound7/1.png">
    
    
      
        
          <link rel="shortcut icon" href="/images/favicon.ico">
        
      
      
        
          <link rel="icon" type="image/png" href="/images/favicon-192x192.png" sizes="192x192">
        
      
      
        
          <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
        
      
    
    <!-- title -->
    <title>07 The VC Dimension</title>
    <!-- async scripts -->
    <!-- Google Analytics -->


    <!-- Umami Analytics -->


    <!-- styles -->
    
<link rel="stylesheet" href="/css/style.css">

    <!-- persian styles -->
    
    <!-- rss -->
    
    
	<!-- mathjax -->
	
<meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="vhdsih" type="application/atom+xml">
</head>

<body class="max-width mx-auto px3 ltr">
    
      <div id="header-post">
  <a id="menu-icon" href="#" aria-label="Menu"><i class="fa-solid fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#" aria-label="Menu"><i class="fa-solid fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" aria-label="Top" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fa-solid fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
        <!--
       --><li><a href="/">Home</a></li><!--
     --><!--
       --><li><a href="/archives/">Articles</a></li><!--
     --><!--
       --><li><a href="/categories/">Categories</a></li><!--
     --><!--
       --><li><a href="/tags/">Tags</a></li><!--
     --><!--
       --><li><a href="/logs/">Logs</a></li><!--
     --><!--
       --><li><a href="/about/">About</a></li><!--
     --><!--
       --><li><a href="/atom.xml">Rss</a></li><!--
     -->
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li><a class="icon" aria-label="Previous post" href="/2018/10/11/mlfound8/"><i class="fa-solid fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li>
        
        
        <li><a class="icon" aria-label="Next post" href="/2018/10/10/mlfound6/"><i class="fa-solid fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" aria-label="Back to top" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fa-solid fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" aria-label="Share post" href="#"><i class="fa-solid fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=https://vhdsih.github.io/2018/10/10/mlfound7/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=https://vhdsih.github.io/2018/10/10/mlfound7/&text=07 The VC Dimension"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=https://vhdsih.github.io/2018/10/10/mlfound7/&title=07 The VC Dimension"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=https://vhdsih.github.io/2018/10/10/mlfound7/&is_video=false&description=07 The VC Dimension"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=07 The VC Dimension&body=Check out this article: https://vhdsih.github.io/2018/10/10/mlfound7/"><i class="fa-solid fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=https://vhdsih.github.io/2018/10/10/mlfound7/&title=07 The VC Dimension"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=https://vhdsih.github.io/2018/10/10/mlfound7/&title=07 The VC Dimension"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=https://vhdsih.github.io/2018/10/10/mlfound7/&title=07 The VC Dimension"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=https://vhdsih.github.io/2018/10/10/mlfound7/&title=07 The VC Dimension"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=https://vhdsih.github.io/2018/10/10/mlfound7/&name=07 The VC Dimension&description=&lt;p&gt;《机器学习基石》系列课程（七）&lt;/p&gt;
&lt;p&gt;我们已经讨论过了，拥有Break Point k的增长函数mh(N)的上界最大是N的k-1次幂，在第6节的最后，我们提出来VC Bound， 利用该公式，我们可以有这样的推论，如果我们当前的Learning问题满足：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;成长函数有Break Point k。&lt;/li&gt;
&lt;li&gt;数据量N足够大&lt;/li&gt;
&lt;li&gt;能够从假设空间中选择一个g，满足Ein非常小（接近0）。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;那么我们就能够说明我们的Learning任务是可行的。当然，这个可行还带有运气的成分（还是会有一定的机率遇到BAD情况，只不过概率很低）。&lt;/p&gt;"><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=https://vhdsih.github.io/2018/10/10/mlfound7/&t=07 The VC Dimension"><i class="fab fa-hacker-news " aria-hidden="true"></i></a></li>
</ul>

    </div>
    
    
      <div id="toc">
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Definition-of-VC-Dimension"><span class="toc-number">1.</span> <span class="toc-text">Definition of VC Dimension</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#VC-Dimension-of-Perceptrons"><span class="toc-number">2.</span> <span class="toc-text">VC Dimension of Perceptrons</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Physical-Intuition-of-VC-Dimension"><span class="toc-number">3.</span> <span class="toc-text">Physical Intuition of VC Dimension</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Interpreting-VC-Dimension"><span class="toc-number">4.</span> <span class="toc-text">Interpreting VC Dimension</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Conclusion"><span class="toc-number">5.</span> <span class="toc-text">Conclusion</span></a></li></ol>
      </div>
    
  </span>
</div>

    
    <div class="content index py4 ">
        
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle p-name" itemprop="name headline">
        07 The VC Dimension
    </h1>



    <div class="meta">
      <span class="author p-author h-card" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span class="p-name" itemprop="name">vhdsih</span>
      </span>
      
    <div class="postdate">
      
        <time datetime="2018-10-10T13:06:44.000Z" class="dt-published" itemprop="datePublished">2018-10-10</time>
        
      
    </div>


      
    <div class="article-category">
        <i class="fa-solid fa-archive"></i>
        <a class="category-link" href="/categories/machine-learning/">machine learning</a>
    </div>


      
    <div class="article-tag">
        <i class="fa-solid fa-tag"></i>
        <a class="p-category" href="/tags/%E6%9E%97%E8%BD%A9%E7%94%B0/" rel="tag">林轩田</a>
    </div>


    </div>
  </header>
  

  <div class="content e-content" itemprop="articleBody">
    <p>《机器学习基石》系列课程（七）</p>
<p>我们已经讨论过了，拥有Break Point k的增长函数mh(N)的上界最大是N的k-1次幂，在第6节的最后，我们提出来VC Bound， 利用该公式，我们可以有这样的推论，如果我们当前的Learning问题满足：</p>
<ol>
<li>成长函数有Break Point k。</li>
<li>数据量N足够大</li>
<li>能够从假设空间中选择一个g，满足Ein非常小（接近0）。</li>
</ol>
<p>那么我们就能够说明我们的Learning任务是可行的。当然，这个可行还带有运气的成分（还是会有一定的机率遇到BAD情况，只不过概率很低）。</p>
<span id="more"></span>

<h2 id="Definition-of-VC-Dimension"><a href="#Definition-of-VC-Dimension" class="headerlink" title="Definition of VC Dimension"></a>Definition of VC Dimension</h2><p>现在，我们为最大的非Break Point取一个正式的名字：VC Dimension，将其记为dvc。此时，如果N小于dvc，那么对于有N个输入的假设空间，一定能够shatter这些数据。任意k大于dvc，k都是H的Break Point。那么此时，我们就可以对成长函数的上界有一个新的表示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mh(N) &lt;= N * dvc; (N &gt;= 2 &amp;&amp; dvc &gt;= 2)</span><br></pre></td></tr></table></figure>

<p>dvc取其它数值的，可以有其它的表示方式。</p>
<p>那么此时，对于之前常常提到的几种情况，其dvc的值分别如下：</p>
<ol>
<li>positive rays： dvc = 1。</li>
<li>positive intervals：dvc = 2。</li>
<li>convex sets：dvc = infinite。</li>
<li>2D Perceptrons：dvc = 3。</li>
</ol>
<p>对于一个好的假设空间来说，它有有限的VC Dimension。此时，如果我们知道我们的Learning任务有一个有限的dvc，那么不管我们的学习算法是什么，不管我们的输入数据的分布是什么，不管我们要学习的目标函数是什么，我们都能保证我们的学习能够进行，因为我们dvc is finite保证了g能够使Ein和Eout大致相等。</p>
<h2 id="VC-Dimension-of-Perceptrons"><a href="#VC-Dimension-of-Perceptrons" class="headerlink" title="VC Dimension of Perceptrons"></a>VC Dimension of Perceptrons</h2><p>我们再回顾一下在二维Perceptron任务上到底发生了什么，我们只有输入线性的输入数据，PLA才能够停止，而我们跑了很多次以后，得到的最终结果是一条线，能够将所有的点正确的分为两类，实际上就是让Ein=0。而另一方面，我们在某一个符合某一个分布，并利用target function生成的数据上进行Learning时，由于2D数据，其dvc=3，也就保证了在N足够大的时候，Ein和Eout是能够大致相等的。以上这两点保证了PLA的可行性。</p>
<p>当然，这只是在2维空间里，那么在更高维度的空间呢？</p>
<p>我们尝试推论d维空间里dvc的大小是多少：1维空间dcv=2，2维空间中dvc=3，那么d为空间呢，是否是d+1呢？</p>
<p>我们要证明这件事，实际上只要分两步就可以：</p>
<ol>
<li>证明dvc &gt;= d+1。</li>
<li>证明dvc &lt;= d+1。</li>
</ol>
<p>我们首先证明1:</p>
<p>如果dvc大于d+1，那么对于d+1个点，必然都能够shatter。我们可以取d+1个点：</p>
<p><img src="1.png" alt="x"> </p>
<p>如果对于任何一个y = [y1， y2，…，yd+1]T，都能找到一个w，令sign(xw) = y即可。因为x是可逆矩阵，因此很简单，直接两边乘以X的逆矩阵就可以。从而我们知道d+1个点都能够被shatter，从而得证。</p>
<p>我们再证明2:</p>
<p>证明2用到了线性代数中一个向量的线性表示的知识。我们取d+2个点，看第d+2个点能否被其它的点线性表示。由此证明出2。</p>
<h2 id="Physical-Intuition-of-VC-Dimension"><a href="#Physical-Intuition-of-VC-Dimension" class="headerlink" title="Physical Intuition of VC Dimension"></a>Physical Intuition of VC Dimension</h2><p>那么VC Dimension的物理意义是什么呢？VC Dimension表示了假设空间的自由度，或者形象地说，就是假设空间有多少个有效的旋钮（参数）我们能够调节（当然，只是一个不准确的描述，可能并不如此）。比如，对于Positive Rays模型，我们的dvc=1，我们只能调节分界点在哪，对于Positive Intervals问题，我们则有两个参数，可以调节左边在哪，右边在哪。</p>
<p>现在，我们就可以用dvc的大小来回答是否能够让Ein和Eout近似相等和我们能够让Ein足够小这两个问题了：</p>
<ol>
<li>如果dvc很小，Ein和Eout一定能够近似相等，但是由于Learning的自由度太小，我们却不一定能够学习到能够让Ein足够小的假设。</li>
<li>同理，如果dvc很大，Ein和Eout则可能相差很远，但是由于Learning的自由度很大，所以能够找到Ein足够小的假设。</li>
</ol>
<p>由此，我们说使用适当的dvc（适当的模型）是十分重要的。</p>
<h2 id="Interpreting-VC-Dimension"><a href="#Interpreting-VC-Dimension" class="headerlink" title="Interpreting VC Dimension"></a>Interpreting VC Dimension</h2><p>现在，我们想更深入了解VC Dimension的意义。我们首先对VC Bound重新描述。</p>
<p><img src="2.png" alt="duita"> </p>
<p>VC Bound实际上说明了坏事请发生的概率很小，我们使用δ表示坏事情发生的概率，那么1 - δ就是好事情发生的概率。那么好事情发生的概率就会很大很大。我们对其做一个简单的代换：</p>
<p><img src="3.png" alt="good"> </p>
<p>我们最终得到了e，其表示Ein和Eout的差值的绝对值大小，由此，我们能够推出Ein和Eout差值的上界，更准确地说，我们有很大的机会将Ein和Eout的差值限制在这个范围内。我们一般更加重视上界的作用。这个公式表明，我们的模型有多么强，那么在generate这个模型的时候，就要付出多大的代价（Penalty for Model Complexity）。通常表示为：Ω(N,H,δ)。</p>
<p><img src="4.png" alt="4.png"> </p>
<p>我们可以画出这样一张图：</p>
<p><img src="5.png" alt="5.png"> </p>
<p>横轴是dvc，纵轴是Error。随着VC维度的升高，模型的Ein越来越小，Eout先小后大，而模型的复杂度则越来越大。而最好的模型则在中间。我们未来会利用这张图来想办法设计更好的机器学习演算法。</p>
<p>所以，不是更复杂的、能力更强的模型性能更好，我们不要追求复杂的Model，我们需要正确使用Ml！</p>
<p>VC Dimension还有另外一层意思：就是资料的复杂度。资料越大，往往error能够限定到更小的范围。在理论上符合要求的数据量需要达到100000*dvc，但是实际上只要10倍的dvc的数据就能达到良好的效果。条件如此宽松的原因如下：</p>
<ol>
<li>我们使用Hoeffding不等式来估计Eout，我们可以在任意分布的数据以及任意目标函数上使用这个不等式，Hoeffding不等式的包容性很高，导致最终结果的包容性高。</li>
<li>我们使用成长函数来替换M，而并没有用真正的假设空间的大小，这允许我们使用任何资料。</li>
<li>我们使用了多项式做上限的上限的上限，而并不是成长函数。</li>
<li>我们仍然使用了union bound，即使我们将重叠的部分计算的很好，仍然还存在糟糕的情况。</li>
</ol>
<p>VC Bound很宽松，但是做的已经很好了。</p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>在这一章中我们介绍了VC Dimension，也就是最大的非Break Point。在Perceptrons上其数值是d+1。物理意义上，dvc告诉我们model有多大的自由度，我们可以使用它来看模型的复杂度以及需要使用多少数据来学习。</p>
<blockquote>
<p>文章内容和图片均来自“国立台湾大学林轩田老师”的《机器学习基石》课程！</p>
</blockquote>
<p>— END —</p>

  </div>
</article>



        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
        
          <li><a href="/">Home</a></li>
        
          <li><a href="/archives/">Articles</a></li>
        
          <li><a href="/categories/">Categories</a></li>
        
          <li><a href="/tags/">Tags</a></li>
        
          <li><a href="/logs/">Logs</a></li>
        
          <li><a href="/about/">About</a></li>
        
          <li><a href="/atom.xml">Rss</a></li>
        
      </ul>
    </div>

    
    
      <div id="toc-footer" style="display: none">
        <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Definition-of-VC-Dimension"><span class="toc-number">1.</span> <span class="toc-text">Definition of VC Dimension</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#VC-Dimension-of-Perceptrons"><span class="toc-number">2.</span> <span class="toc-text">VC Dimension of Perceptrons</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Physical-Intuition-of-VC-Dimension"><span class="toc-number">3.</span> <span class="toc-text">Physical Intuition of VC Dimension</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Interpreting-VC-Dimension"><span class="toc-number">4.</span> <span class="toc-text">Interpreting VC Dimension</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Conclusion"><span class="toc-number">5.</span> <span class="toc-text">Conclusion</span></a></li></ol>
      </div>
    

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=https://vhdsih.github.io/2018/10/10/mlfound7/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=https://vhdsih.github.io/2018/10/10/mlfound7/&text=07 The VC Dimension"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=https://vhdsih.github.io/2018/10/10/mlfound7/&title=07 The VC Dimension"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=https://vhdsih.github.io/2018/10/10/mlfound7/&is_video=false&description=07 The VC Dimension"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=07 The VC Dimension&body=Check out this article: https://vhdsih.github.io/2018/10/10/mlfound7/"><i class="fa-solid fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=https://vhdsih.github.io/2018/10/10/mlfound7/&title=07 The VC Dimension"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=https://vhdsih.github.io/2018/10/10/mlfound7/&title=07 The VC Dimension"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=https://vhdsih.github.io/2018/10/10/mlfound7/&title=07 The VC Dimension"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=https://vhdsih.github.io/2018/10/10/mlfound7/&title=07 The VC Dimension"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=https://vhdsih.github.io/2018/10/10/mlfound7/&name=07 The VC Dimension&description=&lt;p&gt;《机器学习基石》系列课程（七）&lt;/p&gt;
&lt;p&gt;我们已经讨论过了，拥有Break Point k的增长函数mh(N)的上界最大是N的k-1次幂，在第6节的最后，我们提出来VC Bound， 利用该公式，我们可以有这样的推论，如果我们当前的Learning问题满足：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;成长函数有Break Point k。&lt;/li&gt;
&lt;li&gt;数据量N足够大&lt;/li&gt;
&lt;li&gt;能够从假设空间中选择一个g，满足Ein非常小（接近0）。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;那么我们就能够说明我们的Learning任务是可行的。当然，这个可行还带有运气的成分（还是会有一定的机率遇到BAD情况，只不过概率很低）。&lt;/p&gt;"><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=https://vhdsih.github.io/2018/10/10/mlfound7/&t=07 The VC Dimension"><i class="fab fa-hacker-news fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fa-solid fa-bars fa-lg" aria-hidden="true"></i> Menu</a>
        
          <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fa-solid fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fa-solid fa-share-alt fa-lg" aria-hidden="true"></i> Share</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fa-solid fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a>
    </div>

  </div>
</div>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy;
    
    
    2016-2023
    vhdsih
  </div>
  <div class="footer-right">
    <nav>
      <ul>
        <!--
       --><li><a href="/">Home</a></li><!--
     --><!--
       --><li><a href="/archives/">Articles</a></li><!--
     --><!--
       --><li><a href="/categories/">Categories</a></li><!--
     --><!--
       --><li><a href="/tags/">Tags</a></li><!--
     --><!--
       --><li><a href="/logs/">Logs</a></li><!--
     --><!--
       --><li><a href="/about/">About</a></li><!--
     --><!--
       --><li><a href="/atom.xml">Rss</a></li><!--
     -->
      </ul>
    </nav>
  </div>
</footer>

    </div>
    <!-- styles -->



  <link rel="preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" crossorigin="anonymous" onload="this.onload=null;this.rel='stylesheet'"/>


    <!-- jquery -->

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" crossorigin="anonymous"></script>




<!-- clipboard -->

  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.7/clipboard.min.js" crossorigin="anonymous"></script>
  
  <script type="text/javascript">
  $(function() {
    // copy-btn HTML
    var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"Copy to clipboard!\">";
    btn += '<i class="fa-regular fa-clone"></i>';
    btn += '</span>';
    // mount it!
    $(".highlight table").before(btn);
    var clip = new ClipboardJS('.btn-copy', {
      text: function(trigger) {
        return Array.from(trigger.nextElementSibling.querySelectorAll('.code')).reduce((str,it)=>str+it.innerText+'\n','')
      }
    });
    clip.on('success', function(e) {
      e.trigger.setAttribute('aria-label', "Copied!");
      e.clearSelection();
    })
  })
  </script>


<script src="/js/main.js"></script>

<!-- search -->

<!-- Baidu Analytics -->

<!-- Cloudflare Analytics -->

<!-- Disqus Comments -->

<!-- utterances Comments -->

</body>
</html>
